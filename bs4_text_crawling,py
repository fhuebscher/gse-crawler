import requests
from bs4 import BeautifulSoup

def get_text_from_url(url):
    # Get the HTML content of the page
    response = requests.get(url)
    html_content = response.content
    
    # Parse the HTML content with BeautifulSoup
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # Extract all the text from the page and remove HTML tags
    text = soup.get_text(separator='\n')
    
    return text

def get_links_from_url(url):
    # Get the HTML content of the page
    response = requests.get(url)
    html_content = response.content
    
    # Parse the HTML content with BeautifulSoup
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # Find all the hyperlinks in the page
    links = []
    for link in soup.find_all('a'):
        href = link.get('href')
        if href:
            links.append(href)
    
    return links

def get_elements_from_url(url, elements):
    # Get the HTML content of the page
    response = requests.get(url)
    html_content = response.content
    
    # Parse the HTML content with BeautifulSoup
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # Extract the content of all the specified HTML tags
    results = []
    for element in elements:
        for tag in soup.find_all(element):
            tag_text = tag.get_text().strip()
            if tag_text:
                results.append(tag_text)
    
    return results


if __name__ == "__main__":

  url = 'https://www.uni-mannheim.de'
  text = get_text_from_url(url)
  print(text)

  links = get_links_from_url(url)
  print(links)

  # more elements can be added
  elements = ['h1', 'h2']
  headers = get_elements_from_url(url, elements)
  print(headers)
